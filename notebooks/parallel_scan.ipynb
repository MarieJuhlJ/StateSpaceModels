{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "925bec48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import math\n",
    "from ssm.parallel_scan import parallel_scan_naive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1b5d75",
   "metadata": {},
   "source": [
    "We define the following matrices:\n",
    "\n",
    "$$\n",
    "\\bar{A}_0 =\n",
    "\\begin{bmatrix}\n",
    "1 & 0 & 0 \\\\\n",
    "0 & 1 & 0 \\\\\n",
    "0 & 0 & 1\n",
    "\\end{bmatrix}\n",
    "\\quad\n",
    "\\bar{B}_0 =\n",
    "\\begin{bmatrix}\n",
    "6 \\\\\n",
    "1 \\\\\n",
    "2\n",
    "\\end{bmatrix}\n",
    "\\quad\n",
    "C_0 =\n",
    "\\begin{bmatrix}\n",
    "1 & 2 & 3\n",
    "\\end{bmatrix}\n",
    "\\quad\n",
    "u_0 =\n",
    "\\begin{bmatrix}\n",
    "5\n",
    "\\end{bmatrix}\n",
    "\\\\[1em]\n",
    "\\bar{A}_1 =\n",
    "\\begin{bmatrix}\n",
    "3 & 0 & 0 \\\\\n",
    "0 & 1 & 0 \\\\\n",
    "0 & 0 & 2\n",
    "\\end{bmatrix}\n",
    "\\quad\n",
    "\\bar{B}_1 =\n",
    "\\begin{bmatrix}\n",
    "9 \\\\\n",
    "8 \\\\\n",
    "3\n",
    "\\end{bmatrix}\n",
    "\\quad\n",
    "C_1 =\n",
    "\\begin{bmatrix}\n",
    "4 & 5 & 7\n",
    "\\end{bmatrix}\n",
    "\\quad\n",
    "u_1 =\n",
    "\\begin{bmatrix}\n",
    "8\n",
    "\\end{bmatrix}\n",
    "\\\\[1em]\n",
    "\\bar{A}_2 =\n",
    "\\begin{bmatrix}\n",
    "5 & 0 & 0 \\\\\n",
    "0 & 1 & 0 \\\\\n",
    "0 & 0 & 1\n",
    "\\end{bmatrix}\n",
    "\\quad\n",
    "\\bar{B}_2 =\n",
    "\\begin{bmatrix}\n",
    "3 \\\\\n",
    "4 \\\\\n",
    "6\n",
    "\\end{bmatrix}\n",
    "\\quad\n",
    "C_2 =\n",
    "\\begin{bmatrix}\n",
    "1 & 2 & 6\n",
    "\\end{bmatrix}\n",
    "\\quad\n",
    "u_2 =\n",
    "\\begin{bmatrix}\n",
    "3\n",
    "\\end{bmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "985bdd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch\n",
    "A_bar = torch.tensor([[3,1,2], [5,1,1]], dtype=torch.float32, requires_grad=True)\n",
    "B_bar = torch.tensor([[6,1,2], [9,8,3], [3,4,6]], dtype=torch.float32, requires_grad=True)\n",
    "C = torch.tensor([[1,2,3], [4,5,7], [1,2,6]], dtype=torch.float32, requires_grad=True)\n",
    "u = torch.tensor([5,8,3], dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "#numpy\n",
    "A_bar_np = np.array([[1,1,1],[3, 1, 2], [5, 1, 1]], dtype=np.float32)\n",
    "B_bar_np = np.array([[6, 1, 2], [9, 8, 3], [3, 4, 6]], dtype=np.float32)\n",
    "C_np = np.array([[1, 2, 3], [4, 5, 7], [1, 2, 6]], dtype=np.float32)\n",
    "u_np = np.array([5, 8, 3], dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89327a1a",
   "metadata": {},
   "source": [
    "Let us manually calculate the forward pass! we start with the recurrence of the hidden states:\n",
    "$$\n",
    "\\begin{align*}\n",
    "  x_k = \\begin{cases}\n",
    "          \\bar{B}_0 u_0 \\quad & k=0 \\\\\n",
    "          (\\bar{A}_k x_{k-1}) + \\bar{B}_k u_k \\quad &0 < k \\leq L\n",
    "        \\end{cases}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eda50d1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5242b9bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_k = [array([30.,  5., 10.], dtype=float32), array([162.,  69.,  44.], dtype=float32), array([819.,  81.,  62.], dtype=float32)]\n",
      "y_k = [  70. 1301. 1353.]\n"
     ]
    }
   ],
   "source": [
    "def x_k(A_bar, B_bar, u):\n",
    "  x_states = []\n",
    "  for k in range(len(u)):\n",
    "    if k == 0:\n",
    "      x_states.append(B_bar[k] * u[k])\n",
    "    else:\n",
    "      x_states.append((A_bar[k] * x_states[k-1]) + B_bar[k] * u[k])\n",
    "  return x_states\n",
    "\n",
    "hidden_states = x_k(A_bar_np, B_bar_np, u_np)\n",
    "print(f\"x_k = {hidden_states}\")\n",
    "print(f\"y_k = {(C_np * hidden_states).sum(axis=1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff282dd",
   "metadata": {},
   "source": [
    "Let us now dive into the backward pass!\n",
    "We first neeed to define a loss. Let us use an easy one such as\n",
    "$$\n",
    "\\mathcal{L} (\\{y_k\\}_{\\mathbb{N}_L}) = \\sum_{k=0}^L y_k\n",
    "$$\n",
    "With this simple loss, we have $\\frac{\\partial \\mathcal{L}}{\\partial y_k} = 1$. And by extension the direct path from $x_k \\rightarrow \\mathcal{L}$ is $\\frac{\\partial \\mathcal{L}}{\\partial y_k}\\frac{\\partial y_k}{\\partial x_k} = c_k$\n",
    "\n",
    "We want to onbtain $\\nabla_{x_k} \\mathcal{L}$, $\\nabla_{\\bar{A}_k} \\mathcal{L}$ and $\\nabla_{\\bar{B}_k} \\mathcal{L}$. They are:\n",
    "$$\n",
    "\\begin{align*}\n",
    "  \\nabla_{x_k} \\mathcal{L} &=\\frac{\\partial \\mathcal{L}}{\\partial x_k} \\bar{A}_{k+1} \\nabla_{x_{k+1}} \\mathcal{L}\\\\\n",
    "  \\nabla_{\\bar{A}_k}  \\mathcal{L} &= x_{k-1} \\cdot \\nabla_{x_k} \\mathcal{L}\\\\\n",
    "  \\nabla_{\\bar{B}_k}  \\mathcal{L} &= u_{k} \\nabla_{x_k} \\mathcal{L}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "15dad87a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nabla_x L = \n",
      "[[28.  9. 29.]\n",
      " [ 9.  7. 13.]\n",
      " [ 1.  2.  6.]]\n",
      "nabla_a_bar L =\n",
      "   [0. 0. 0.]\n",
      "   [270.  35. 130.]\n",
      "   [162. 138. 264.]\n",
      "nabla_b_bar L =\n",
      "   [140.  45. 145.]\n",
      "   [ 72.  56. 104.]\n",
      "   [ 3.  6. 18.]\n"
     ]
    }
   ],
   "source": [
    "def nabla_x_k(A_bar, dl_dx, x_k):\n",
    "  grad_x = np.zeros_like(x_k)\n",
    "  for k in reversed(range(len(dl_dx))):\n",
    "    if k == len(dl_dx) - 1:\n",
    "      grad_x[k] =dl_dx[k]\n",
    "    else:\n",
    "      grad_x[k] =A_bar[k+1] * grad_x[k+1] + dl_dx[k]\n",
    "  return grad_x\n",
    "\n",
    "def nabla_a_k(x_k, grad_x, A_bar):\n",
    "  grad_A_bar = []\n",
    "  for k in range(len(x_k)):\n",
    "    if k == 0:\n",
    "      grad_A_bar.append(np.zeros_like(A_bar[0]))\n",
    "    else:\n",
    "      grad_A_bar.append(x_k[k-1] * grad_x[k])\n",
    "  return grad_A_bar\n",
    "\n",
    "def nabla_b_k(u_k, grad_x):\n",
    "  grad_B_bar = []\n",
    "  for k in range(len(u_k)):\n",
    "      grad_B_bar.append(u_k[k] * grad_x[k])\n",
    "  return grad_B_bar\n",
    "\n",
    "grad_x = nabla_x_k(A_bar_np, C_np, hidden_states)\n",
    "grad_A_bar = nabla_a_k(hidden_states, grad_x, A_bar_np)\n",
    "grad_B_bar = nabla_b_k(u_np, grad_x)\n",
    "\n",
    "print(f\"nabla_x L = \\n{grad_x}\")\n",
    "print(f\"nabla_a_bar L =\")\n",
    "for row in grad_A_bar:\n",
    "    print(\"  \", row)\n",
    "print(f\"nabla_b_bar L =\")\n",
    "for row in grad_B_bar:\n",
    "    print(\"  \", row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8a9e7e",
   "metadata": {},
   "source": [
    "Let us see if our implemented torch autograd function is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9610fc39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward pass:\n",
      "tensor([  70., 1301., 1353.], grad_fn=<parallel_scan_naiveBackward>)\n",
      "Gradient wrt A_bar:\n",
      "tensor([[270.,  35., 130.],\n",
      "        [162., 138., 264.]])\n",
      "Gradient wrt B_bar:\n",
      "tensor([[140.,  45., 145.],\n",
      "        [ 72.,  56., 104.],\n",
      "        [  3.,   6.,  18.]])\n"
     ]
    }
   ],
   "source": [
    "# Reset gradients before backward\n",
    "A_bar.grad = None\n",
    "B_bar.grad = None\n",
    "u.grad = None\n",
    "C.grad = None\n",
    "\n",
    "result = parallel_scan_naive.apply(A_bar, B_bar, u, C)\n",
    "loss = result.sum()\n",
    "loss.backward()\n",
    "print(\"Forward pass:\")\n",
    "print(result)\n",
    "print(\"Gradient wrt A_bar:\")\n",
    "print(A_bar.grad)\n",
    "\n",
    "print(\"Gradient wrt B_bar:\")\n",
    "print(B_bar.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb15836",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DTU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
